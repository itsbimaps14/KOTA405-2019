{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b924397c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-14 23:53:05.898244: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7dabb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "bert_ABSA(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(105879, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inisialisasi pre-trained model BERT\n",
    "from ABSA_SentimentMultiEmiten.model.bert import bert_ABSA\n",
    "from ABSA_SentimentMultiEmiten.data.dataset import dataset_ABSA\n",
    "\n",
    "DEVICE = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "\n",
    "pretrained_model_name = \"bert-base-multilingual-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)\n",
    "model_ABSA = bert_ABSA(pretrained_model_name)\n",
    "model_ABSA.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a31b02fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "def load_model(model, path):\n",
    "    model.load_state_dict(torch.load(path), strict=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "055faeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function untuk embersihkan kalimat\n",
    "def clean_sentences(sentences, aspect):\n",
    "  new_sentences = []\n",
    "\n",
    "  for sentence in sentences:\n",
    "    if ((aspect in sentence)):\n",
    "      index = sentence.index(aspect)\n",
    "      emiten = (sentence[index-1].isalpha() == False) and (sentence[index+4].isalpha() == False) \n",
    "      if(emiten):\n",
    "        new_sentences.append(sentence)\n",
    "  return new_sentences\n",
    "\n",
    "# Function untuk memisahkan kalimat menjadi beberapa token\n",
    "def split_sentence(article):\n",
    "  tokens = nltk.tokenize.sent_tokenize(article)\n",
    "  return tokens\n",
    "\n",
    "# Function untuk preprocessing teks input\n",
    "def preprocessing_text(article, aspect):\n",
    "  # Hapus URL\n",
    "  if ('deviden' not in article) and ('dividen' not in article):\n",
    "    article = re.sub('\\S+.com|\\S+.co.id|\\S+.co|\\S+.id', '.', article)\n",
    "#   article = re.sub('\\S+.com|\\S+.co.id|\\S+.co|\\S+.id', '.', article)\n",
    "\n",
    "  # Hapus titik yang bukan pemisah kalimat \n",
    "  article = article.replace(\"PT.\", \"PT\").replace(\"Tbk.\", \"Tbk\")\n",
    "  for number in range(100):\n",
    "    article = article.replace(\" \"+str(number)+\". \", \" \" )\n",
    "\n",
    "  # Ambil kalimat yang mengandung emiten\n",
    "  sentences = split_sentence(article)\n",
    "  arr_sentence_dirt = clean_sentences(sentences, aspect)\n",
    "\n",
    "  arr_sentence_clean = []\n",
    "  arr_sentence_clean.extend(arr_sentence_dirt)\n",
    "  i = 0\n",
    "  while (i < (len(arr_sentence_clean))):\n",
    "    # Menghapus semua karakter selain huruf, angka, spasi, dan titik\n",
    "    arr_sentence_clean[i] = re.sub(r'[^\\w\\d\\s\\.]+', '', arr_sentence_clean[i]) \n",
    "    \n",
    "    # Mengubah kalimat menjadi huruf kecil\n",
    "    arr_sentence_clean[i] = arr_sentence_clean[i].lower()\n",
    "    \n",
    "    # Menghapus angka\n",
    "    arr_sentence_clean[i] = ''.join([x for x in arr_sentence_clean[i] if not x.isdigit()])\n",
    "    i = i+1\n",
    "\n",
    "  return arr_sentence_clean, arr_sentence_dirt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ddf8f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediksi kalimat\n",
    "def predict(sentence, aspect, tokenizer):\n",
    "    t1 = tokenizer.tokenize(sentence)\n",
    "    t2 = tokenizer.tokenize(aspect)\n",
    "\n",
    "    word_pieces = ['[cls]']\n",
    "    word_pieces += t1\n",
    "    word_pieces += ['[sep]']\n",
    "    word_pieces += t2\n",
    "\n",
    "    segment_tensor = [0] + [0]*len(t1) + [0] + [1]*len(t2)\n",
    "\n",
    "    ids = tokenizer.convert_tokens_to_ids(word_pieces)\n",
    "    input_tensor = torch.tensor([ids]).to(DEVICE)\n",
    "    segment_tensor = torch.tensor(segment_tensor).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model_ABSA(input_tensor, None, None, segments_tensors=segment_tensor)\n",
    "        _, predictions = torch.max(outputs, dim=1)\n",
    "    \n",
    "    return word_pieces, predictions, outputs\n",
    "\n",
    "# Controller predict\n",
    "def predict_sentence(s, aspect):\n",
    "  arr_sentence_clean, arr_sentence_dirt  = preprocessing_text(s, aspect)\n",
    "\n",
    "  output = []\n",
    "  i = 0\n",
    "  sentiments = [\"Negative\", \"Neutral\", \"Positive\"]\n",
    "  \n",
    "  while (i < (len(arr_sentence_clean))):\n",
    "    x, y, z = predict(arr_sentence_clean[i] , aspect, tokenizer)\n",
    "    \n",
    "    y_str = str(y)\n",
    "    sentiment = sentiments[int(y_str[8])]\n",
    "    output.append({\n",
    "      \"sentence\": arr_sentence_dirt[i].strip(),\n",
    "      \"aspect\": aspect,\n",
    "      \"sentiment\": sentiment\n",
    "    })\n",
    "    i = i+1\n",
    "  \n",
    "  return output\n",
    "\n",
    "# Mengambil data emiten\n",
    "def get_data_emiten():\n",
    "  return pd.read_csv(\"./data/daftar_emiten.csv\")\n",
    "\n",
    "# Prediksi artikel\n",
    "def get_final_sentiment_artikel(artikel, data_emiten=[]):\n",
    "  output = []\n",
    "\n",
    "  if(data_emiten==[]):\n",
    "    data_emiten = get_data_emiten().KodeEmiten\n",
    "  else: \n",
    "    data_emiten = data_emiten.split()\n",
    "  for emiten in data_emiten:\n",
    "    if(emiten in artikel):\n",
    "      output.extend(predict_sentence(artikel, emiten))\n",
    "  \n",
    "  return json.dumps(output, indent = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6beb40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-multilingual-2.pkl\"\n",
    "\n",
    "model_ABSA = load_model(model_ABSA, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c72b6bee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      " {\n",
      "  \"sentence\": \"Ipotnews - Emiten BBHI dan LPPF tercatat menjadi jawara dalam jajaran top gainers di indeks Kompas100 pada Rabu (7/6) pagi.\",\n",
      "  \"aspect\": \"BBHI\",\n",
      "  \"sentiment\": \"Positive\"\n",
      " },\n",
      " {\n",
      "  \"sentence\": \"Mengutip data IPOT 1 pukul 09.54 WIB, harga saham BBHI menguat 50 poin menjadi 1.125, atau naik 4,7%.\",\n",
      "  \"aspect\": \"BBHI\",\n",
      "  \"sentiment\": \"Positive\"\n",
      " },\n",
      " {\n",
      "  \"sentence\": \"Sebagaimana diketahui, emiten bank digital, PT Allo Bank Indonesia Tbk (BBHI) berhasil meningkatkan performa kinerja pada kuartal I 2023 dengan peningkatan laba.\",\n",
      "  \"aspect\": \"BBHI\",\n",
      "  \"sentiment\": \"Positive\"\n",
      " },\n",
      " {\n",
      "  \"sentence\": \"BBHI mencatatkan pertumbuhan laba bersih sepanjang tiga bulan pertama 2023 sebesar 21% secara tahunan (year-on-year/yoy) mencapai Rp90,49 miliar dari posisi sebelumnya Rp75 miliar.\",\n",
      "  \"aspect\": \"BBHI\",\n",
      "  \"sentiment\": \"Positive\"\n",
      " },\n",
      " {\n",
      "  \"sentence\": \"Salah satu penopang pertumbuhan laba BBHI adalah lonjakan  pendapatan bunga hingga 204% secara tahunan menjadi Rp313,63 miliar pada kuartal I 2023 dari Rp103,3 miliar pada periode yang sama di tahun sebelumnya.\",\n",
      "  \"aspect\": \"BBHI\",\n",
      "  \"sentiment\": \"Positive\"\n",
      " },\n",
      " {\n",
      "  \"sentence\": \"Namun sebaliknya BBHI juga mencatatkan peningkatan beban bunga sebesar 241% menjadi Rp76,55 miliar.\",\n",
      "  \"aspect\": \"BBHI\",\n",
      "  \"sentiment\": \"Neutral\"\n",
      " },\n",
      " {\n",
      "  \"sentence\": \"Ipotnews - Emiten BBHI dan LPPF tercatat menjadi jawara dalam jajaran top gainers di indeks Kompas100 pada Rabu (7/6) pagi.\",\n",
      "  \"aspect\": \"LPPF\",\n",
      "  \"sentiment\": \"Positive\"\n",
      " },\n",
      " {\n",
      "  \"sentence\": \"Menyusul berikutnya adalah harga saham LPPF menguat 120 poin menjadi 3.410, atau naik 3,6%.\",\n",
      "  \"aspect\": \"LPPF\",\n",
      "  \"sentiment\": \"Positive\"\n",
      " },\n",
      " {\n",
      "  \"sentence\": \"Sementara itu, pada kuartal I 2023, PT Matahari Department Store Tbk (LPPF) memperluas bisnisnya dengan membuka dua gerai baru di Balikpapan, Kalimantan Timur dan Kuta, Bali.\",\n",
      "  \"aspect\": \"LPPF\",\n",
      "  \"sentiment\": \"Neutral\"\n",
      " }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "teks = \"\"\"Ipotnews - Emiten BBHI dan LPPF tercatat menjadi jawara dalam jajaran top gainers di indeks Kompas100 pada Rabu (7/6) pagi.\n",
    "Mengutip data IPOT 1 pukul 09.54 WIB, harga saham BBHI menguat 50 poin menjadi 1.125, atau naik 4,7%. Menyusul berikutnya adalah harga saham LPPF menguat 120 poin menjadi 3.410, atau naik 3,6%.\n",
    "Sebagaimana diketahui, emiten bank digital, PT Allo Bank Indonesia Tbk (BBHI) berhasil meningkatkan performa kinerja pada kuartal I 2023 dengan peningkatan laba.\n",
    "BBHI mencatatkan pertumbuhan laba bersih sepanjang tiga bulan pertama 2023 sebesar 21% secara tahunan (year-on-year/yoy) mencapai Rp90,49 miliar dari posisi sebelumnya Rp75 miliar.\n",
    "Salah satu penopang pertumbuhan laba BBHI adalah lonjakan  pendapatan bunga hingga 204% secara tahunan menjadi Rp313,63 miliar pada kuartal I 2023 dari Rp103,3 miliar pada periode yang sama di tahun sebelumnya.\n",
    "Namun sebaliknya BBHI juga mencatatkan peningkatan beban bunga sebesar 241% menjadi Rp76,55 miliar. Meskipun demikian, pendapatan bunga bersih bank tercatat tetap menebal 193% menjadi Rp237,08 miliar dibandingkan dengan kuartal I 2022 Rp80,83 miliar.\n",
    "Selain itu, angka kerugian penurunan nilai aset keuangan ( impairment ) Allobank juga susut 70% menjadi Rp3,94 miliar hingga Maret 2023, dari Rp13,21 miliar pada akhir Maret 2022.\n",
    "Sementara itu, pada kuartal I 2023, PT Matahari Department Store Tbk (LPPF) memperluas bisnisnya dengan membuka dua gerai baru di Balikpapan, Kalimantan Timur dan Kuta, Bali. Pembukaan gerai baru di Plaza Balikpapan dilakukan pada Rabu (05/04/2023) dan di Discovery Shopping Mall, Kuta, pada 6 April 2023.\n",
    "\"Dengan membawa tema 'Time To Grow' di tahun ini, kami membuka gerai baru keenam dan ketujuh dari program pembukaan gerai yang sudah direncanakan perseroan. Melalui dua gerai baru ini, kami ingin menghadirkan berbagai pilihan dan pengalaman berbelanja, serta menjadikan Matahari sebagai pilihan utama berbelanja di musim Lebaran ini,\" kata CEO Matahari Terry O'Connor dalam keterangan resminya, Rabu (5/4/2023).\n",
    "Dengan konsep baru yang lebih segar, menurut Terry, kedua toko ini menawarkan merchandise yang diperbarui dan pengalaman berbelanja pelanggan yang lebih baik. Matahari menggunakan sistem pencahayaan 100% LED sebagai komitmen perusahaan terhadap lingkungan.\n",
    "\"Kami percaya, kehadiran dua gerai dengan karakteristik modern ini akan menghadirkan pilihan belanja yang berbeda bagi masyarakat setempat,\" tutur dia.\n",
    "\"\"\"\n",
    "\n",
    "print(get_final_sentiment_artikel(teks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6604f8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
