{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4824a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-19 22:59:20.981267: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import tensorflow\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from transformers import AutoTokenizer, BertTokenizer \n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from ABSA_SentimentMultiEmiten.model.bert import bert_ABSA\n",
    "from ABSA_SentimentMultiEmiten.data.dataset import dataset_ABSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ab941fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow\t:  2.4.1\n",
      "Torch\t\t:  1.1.0\n",
      "Device\t\t:  cuda:1\n",
      "GPU\t\t:  Tesla T4\n",
      "CUDA\t\t:  9.0.176\n"
     ]
    }
   ],
   "source": [
    "# Menentukan device yang akan digunakan untuk melakukan komputasi\n",
    "DEVICE = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Tensorflow\\t: \", tensorflow.__version__)\n",
    "print(\"Torch\\t\\t: \", torch.__version__)\n",
    "print(\"Device\\t\\t: \", DEVICE)\n",
    "print(\"GPU\\t\\t: \", torch.cuda.get_device_name())\n",
    "print(\"CUDA\\t\\t: \", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86d08072",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 16\n",
    "lr = 0.00002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4284ec7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inisialisasi pre-trained model IndoBERT\n",
    "model_name = \"bert-multilingual-2.pkl\"\n",
    "pretrained_model_name = \"bert-base-multilingual-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)\n",
    "model_ABSA = bert_ABSA(pretrained_model_name)\n",
    "model_ABSA.to(DEVICE)\n",
    "optimizer_ABSA = torch.optim.Adam(model_ABSA.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f874968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function untuk load model\n",
    "def load_model(model, path):\n",
    "    model.load_state_dict(torch.load(path), strict=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e61979af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengubah dataset menjadi beberapa mini-batch\n",
    "def create_mini_batch(samples):\n",
    "    ids_tensors = [s[1] for s in samples]\n",
    "    ids_tensors = pad_sequence(ids_tensors, batch_first=True)\n",
    "\n",
    "    segments_tensors = [s[2] for s in samples]\n",
    "    segments_tensors = pad_sequence(segments_tensors, batch_first=True)\n",
    "\n",
    "    label_ids = torch.stack([s[3] for s in samples])\n",
    "    \n",
    "    masks_tensors = torch.zeros(ids_tensors.shape, dtype=torch.long)\n",
    "    masks_tensors = masks_tensors.masked_fill(ids_tensors != 0, 1)\n",
    "\n",
    "    return ids_tensors, segments_tensors, masks_tensors, label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "884d5a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function untuk pengujian model\n",
    "def test_model_ABSA(loader):\n",
    "    pred = []\n",
    "    truth = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Pengulangan setiap mini-batch\n",
    "        for data in loader:\n",
    "            ids_tensors, segments_tensors, masks_tensors, label_ids = data\n",
    "            ids_tensors = ids_tensors.to(DEVICE)\n",
    "            segments_tensors = segments_tensors.to(DEVICE)\n",
    "            masks_tensors = masks_tensors.to(DEVICE)\n",
    "\n",
    "            outputs = model_ABSA(ids_tensors, None, masks_tensors=masks_tensors, segments_tensors=segments_tensors)\n",
    "            \n",
    "            _, predictions = torch.max(outputs, dim=1)\n",
    "\n",
    "            pred += list([int(i) for i in predictions])\n",
    "            truth += list([int(i) for i in label_ids])\n",
    "\n",
    "    return truth, pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8e0a0b",
   "metadata": {},
   "source": [
    "## Load Data Testing Unbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e85810fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inisialisasi dataset eksperiment max\n",
    "emiten_max = dataset_ABSA(pd.read_csv(\"data/data_eksperimen_kalimat/data_lama/data_experiment_max.csv\"), tokenizer)\n",
    "test_max = ConcatDataset([emiten_max])\n",
    "loader_max = DataLoader(test_max, batch_size=bs, collate_fn=create_mini_batch, shuffle = True)\n",
    "\n",
    "# Inisialisasi dataset eksperiment avg\n",
    "emiten_avg = dataset_ABSA(pd.read_csv(\"data/data_eksperimen_kalimat/data_lama/data_experiment_avg.csv\"), tokenizer)\n",
    "test_avg = ConcatDataset([emiten_avg])\n",
    "loader_avg = DataLoader(test_avg, batch_size=bs, collate_fn=create_mini_batch, shuffle = True)\n",
    "\n",
    "# Inisialisasi dataset eksperiment min\n",
    "emiten_min = dataset_ABSA(pd.read_csv(\"data/data_eksperimen_kalimat/data_lama/data_experiment_min.csv\"), tokenizer)\n",
    "test_min = ConcatDataset([emiten_min])\n",
    "loader_min = DataLoader(test_min, batch_size=bs, collate_fn=create_mini_batch, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ccb702",
   "metadata": {},
   "source": [
    "## Load Data Testing Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f9db6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inisialisasi dataset eksperiment max\n",
    "emiten_max_b = dataset_ABSA(pd.read_csv(\"data/data_eksperimen_kalimat/data_lama/data_experiment_max_balance.csv\"), tokenizer)\n",
    "test_max_b = ConcatDataset([emiten_max_b])\n",
    "loader_max_b = DataLoader(test_max_b, batch_size=bs, collate_fn=create_mini_batch, shuffle = True)\n",
    "\n",
    "# Inisialisasi dataset eksperiment avg\n",
    "emiten_avg_b = dataset_ABSA(pd.read_csv(\"data/data_eksperimen_kalimat/data_lama/data_experiment_avg_balance.csv\"), tokenizer)\n",
    "test_avg_b = ConcatDataset([emiten_avg_b])\n",
    "loader_avg_b = DataLoader(test_avg_b, batch_size=bs, collate_fn=create_mini_batch, shuffle = True)\n",
    "\n",
    "# Inisialisasi dataset eksperiment min\n",
    "emiten_min_b = dataset_ABSA(pd.read_csv(\"data/data_eksperimen_kalimat/data_lama/data_experiment_min_balance.csv\"), tokenizer)\n",
    "test_min_b = ConcatDataset([emiten_min_b])\n",
    "loader_min_b = DataLoader(test_min_b, batch_size=bs, collate_fn=create_mini_batch, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3f2af23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ABSA = load_model(model_ABSA, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37ce25e",
   "metadata": {},
   "source": [
    "## Classification Report Unbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e44a7e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      1687\n",
      "           1       0.91      0.96      0.93       465\n",
      "           2       1.00      0.96      0.98      2662\n",
      "\n",
      "    accuracy                           0.97      4814\n",
      "   macro avg       0.95      0.97      0.96      4814\n",
      "weighted avg       0.98      0.97      0.97      4814\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report eksperiment max\n",
    "x, y = test_model_ABSA(loader_max)\n",
    "print(classification_report(x, y, target_names=[str(i) for i in range(3)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d6e75c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93       917\n",
      "           1       0.73      0.97      0.84      1058\n",
      "           2       0.98      0.81      0.89      2292\n",
      "\n",
      "    accuracy                           0.88      4267\n",
      "   macro avg       0.87      0.91      0.89      4267\n",
      "weighted avg       0.90      0.88      0.88      4267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report eksperiment avg\n",
    "x, y = test_model_ABSA(loader_avg)\n",
    "print(classification_report(x, y, target_names=[str(i) for i in range(3)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e938ec46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91       828\n",
      "           1       0.71      0.96      0.81      1040\n",
      "           2       0.97      0.76      0.85      1887\n",
      "\n",
      "    accuracy                           0.85      3755\n",
      "   macro avg       0.86      0.88      0.86      3755\n",
      "weighted avg       0.88      0.85      0.85      3755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report eksperiment min\n",
    "x, y = test_model_ABSA(loader_min)\n",
    "print(classification_report(x, y, target_names=[str(i) for i in range(3)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd84dea",
   "metadata": {},
   "source": [
    "## Classification Report Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be548316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       465\n",
      "           1       0.98      0.96      0.97       465\n",
      "           2       0.99      0.96      0.98       465\n",
      "\n",
      "    accuracy                           0.97      1395\n",
      "   macro avg       0.97      0.97      0.97      1395\n",
      "weighted avg       0.97      0.97      0.97      1395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report eksperiment max balanced\n",
    "x, y = test_model_ABSA(loader_max_b)\n",
    "print(classification_report(x, y, target_names=[str(i) for i in range(3)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fe749d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       916\n",
      "           1       0.84      0.97      0.90       916\n",
      "           2       0.95      0.81      0.87       916\n",
      "\n",
      "    accuracy                           0.91      2748\n",
      "   macro avg       0.92      0.91      0.91      2748\n",
      "weighted avg       0.92      0.91      0.91      2748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report eksperiment avg balanced\n",
    "x, y = test_model_ABSA(loader_avg_b)\n",
    "print(classification_report(x, y, target_names=[str(i) for i in range(3)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdee8e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94       824\n",
      "           1       0.79      0.96      0.87       824\n",
      "           2       0.95      0.75      0.84       824\n",
      "\n",
      "    accuracy                           0.88      2472\n",
      "   macro avg       0.89      0.88      0.88      2472\n",
      "weighted avg       0.89      0.88      0.88      2472\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report eksperiment min balanced\n",
    "x, y = test_model_ABSA(loader_min_b)\n",
    "print(classification_report(x, y, target_names=[str(i) for i in range(3)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
