{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b924397c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-21 22:30:32.593063: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7dabb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "bert_ABSA(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(31923, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inisialisasi pre-trained model BERT\n",
    "from ABSA_SentimentMultiEmiten.model.bert import bert_ABSA\n",
    "from ABSA_SentimentMultiEmiten.data.dataset import dataset_ABSA\n",
    "\n",
    "DEVICE = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "\n",
    "pretrained_model_name = \"indolem/indobert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)\n",
    "model_ABSA = bert_ABSA(pretrained_model_name)\n",
    "model_ABSA.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a31b02fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "def load_model(model, path):\n",
    "    model.load_state_dict(torch.load(path, map_location='cuda:2'), strict=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6beb40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"indolem-indobert-gs/indolem-indobert-gs-1.pkl\"\n",
    "model_ABSA = load_model(model_ABSA, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "055faeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function untuk embersihkan kalimat\n",
    "def clean_sentences(sentences, aspect):\n",
    "  new_sentences = []\n",
    "\n",
    "  for sentence in sentences:\n",
    "    if ((aspect in sentence)):\n",
    "      index = sentence.index(aspect)\n",
    "      emiten = (sentence[index-1].isalpha() == False) and (sentence[index+4].isalpha() == False) \n",
    "      if(emiten):\n",
    "        new_sentences.append(sentence)\n",
    "  return new_sentences\n",
    "\n",
    "# Function untuk memisahkan kalimat menjadi beberapa token\n",
    "def split_sentence(article):\n",
    "  tokens = nltk.tokenize.sent_tokenize(article)\n",
    "  return tokens\n",
    "\n",
    "# Function untuk preprocessing teks input\n",
    "def preprocessing_text(article, aspect):\n",
    "  # Hapus URL\n",
    "  if ('deviden' not in article) and ('dividen' not in article):\n",
    "    article = re.sub('\\S+.com|\\S+.co.id|\\S+.co|\\S+.id', '.', article)\n",
    "#   article = re.sub('\\S+.com|\\S+.co.id|\\S+.co|\\S+.id', '.', article)\n",
    "\n",
    "  # Hapus titik yang bukan pemisah kalimat \n",
    "  article = article.replace(\"PT.\", \"PT\").replace(\"Tbk.\", \"Tbk\")\n",
    "  for number in range(100):\n",
    "    article = article.replace(\" \"+str(number)+\". \", \" \" )\n",
    "\n",
    "  # Ambil kalimat yang mengandung emiten\n",
    "  sentences = split_sentence(article)\n",
    "  arr_sentence_dirt = clean_sentences(sentences, aspect)\n",
    "\n",
    "  arr_sentence_clean = []\n",
    "  arr_sentence_clean.extend(arr_sentence_dirt)\n",
    "  i = 0\n",
    "  while (i < (len(arr_sentence_clean))):\n",
    "    # Menghapus semua karakter selain huruf, angka, spasi, dan titik\n",
    "    arr_sentence_clean[i] = re.sub(r'[^\\w\\d\\s\\.]+', '', arr_sentence_clean[i]) \n",
    "    \n",
    "    # Mengubah kalimat menjadi huruf kecil\n",
    "    arr_sentence_clean[i] = arr_sentence_clean[i].lower()\n",
    "    \n",
    "    # Menghapus angka\n",
    "    arr_sentence_clean[i] = ''.join([x for x in arr_sentence_clean[i] if not x.isdigit()])\n",
    "    i = i+1\n",
    "\n",
    "  return arr_sentence_clean, arr_sentence_dirt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ddf8f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediksi kalimat\n",
    "def predict(sentence, aspect, tokenizer):\n",
    "    t1 = tokenizer.tokenize(sentence)\n",
    "    t2 = tokenizer.tokenize(aspect)\n",
    "\n",
    "    word_pieces = ['[cls]']\n",
    "    word_pieces += t1\n",
    "    word_pieces += ['[sep]']\n",
    "    word_pieces += t2\n",
    "\n",
    "    segment_tensor = [0] + [0]*len(t1) + [0] + [1]*len(t2)\n",
    "\n",
    "    ids = tokenizer.convert_tokens_to_ids(word_pieces)\n",
    "    input_tensor = torch.tensor([ids]).to(DEVICE)\n",
    "    segment_tensor = torch.tensor(segment_tensor).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model_ABSA(input_tensor, None, None, segments_tensors=segment_tensor)\n",
    "        _, predictions = torch.max(outputs, dim=1)\n",
    "    \n",
    "    return word_pieces, predictions, outputs\n",
    "\n",
    "# Controller predict\n",
    "def predict_sentence(s, aspect):\n",
    "  arr_sentence_clean, arr_sentence_dirt  = preprocessing_text(s, aspect)\n",
    "\n",
    "  output = []\n",
    "  i = 0\n",
    "  sentiments = [\"Negative\", \"Neutral\", \"Positive\"]\n",
    "  \n",
    "  while (i < (len(arr_sentence_clean))):\n",
    "    x, y, z = predict(arr_sentence_clean[i] , aspect, tokenizer)\n",
    "    \n",
    "    y_str = str(y)\n",
    "    sentiment = sentiments[int(y_str[8])]\n",
    "    output.append({\n",
    "      \"sentence\": arr_sentence_dirt[i].strip(),\n",
    "      \"aspect\": aspect,\n",
    "      \"sentiment\": sentiment\n",
    "    })\n",
    "    i = i+1\n",
    "  \n",
    "  return output\n",
    "\n",
    "# Mengambil data emiten\n",
    "def get_data_emiten():\n",
    "  return pd.read_csv(\"./data/daftar_emiten.csv\")\n",
    "\n",
    "# Prediksi artikel\n",
    "def get_final_sentiment_artikel(artikel, data_emiten=[]):\n",
    "  output = []\n",
    "\n",
    "  if(data_emiten==[]):\n",
    "    data_emiten = get_data_emiten().KodeEmiten\n",
    "  else: \n",
    "    data_emiten = data_emiten.split()\n",
    "  for emiten in data_emiten:\n",
    "    if(emiten in artikel):\n",
    "      output.extend(predict_sentence(artikel, emiten))\n",
    "  \n",
    "  return json.dumps(output, indent = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02e451ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      " {\n",
      "  \"sentence\": \"Saham BBCA menguat 777 point menjadi 7.777 naik 10%, sedangkan saham BBRI mengalami netsell dengan nilai sebesar 10 Milyar rupiah, dan BBHI tidak terdapat pergerakan yang signifikan\",\n",
      "  \"aspect\": \"BBCA\",\n",
      "  \"sentiment\": \"Positive\"\n",
      " },\n",
      " {\n",
      "  \"sentence\": \"Saham BBCA menguat 777 point menjadi 7.777 naik 10%, sedangkan saham BBRI mengalami netsell dengan nilai sebesar 10 Milyar rupiah, dan BBHI tidak terdapat pergerakan yang signifikan\",\n",
      "  \"aspect\": \"BBHI\",\n",
      "  \"sentiment\": \"Neutral\"\n",
      " },\n",
      " {\n",
      "  \"sentence\": \"Saham BBCA menguat 777 point menjadi 7.777 naik 10%, sedangkan saham BBRI mengalami netsell dengan nilai sebesar 10 Milyar rupiah, dan BBHI tidak terdapat pergerakan yang signifikan\",\n",
      "  \"aspect\": \"BBRI\",\n",
      "  \"sentiment\": \"Negative\"\n",
      " }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "teks = \"Saham BBCA menguat 777 point menjadi 7.777 naik 10%, sedangkan saham BBRI mengalami netsell dengan nilai sebesar 10 Milyar rupiah, dan BBHI tidak terdapat pergerakan yang signifikan\"\n",
    "\n",
    "print(get_final_sentiment_artikel(teks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c72b6bee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      " {\n",
      "  \"sentence\": \"Ipotnews - Emiten BBHI dan LPPF tercatat menjadi jawara dalam jajaran top gainers di indeks Kompas100 pada Rabu (7/6) pagi.\",\n",
      "  \"aspect\": \"BBHI\",\n",
      "  \"sentiment\": \"Positive\"\n",
      " },\n",
      " {\n",
      "  \"sentence\": \"Mengutip data IPOT 1 pukul 09.54 WIB, harga saham BBHI menguat 50 poin menjadi 1.125, atau naik 4,7%.\",\n",
      "  \"aspect\": \"BBHI\",\n",
      "  \"sentiment\": \"Positive\"\n",
      " },\n",
      " {\n",
      "  \"sentence\": \"Sebagaimana diketahui, emiten bank digital, PT Allo Bank Indonesia Tbk (BBHI) berhasil meningkatkan performa kinerja pada kuartal I 2023 dengan peningkatan laba.\",\n",
      "  \"aspect\": \"BBHI\",\n",
      "  \"sentiment\": \"Positive\"\n",
      " },\n",
      " {\n",
      "  \"sentence\": \"BBHI mencatatkan pertumbuhan laba bersih sepanjang tiga bulan pertama 2023 sebesar 21% secara tahunan (year-on-year/yoy) mencapai Rp90,49 miliar dari posisi sebelumnya Rp75 miliar.\",\n",
      "  \"aspect\": \"BBHI\",\n",
      "  \"sentiment\": \"Positive\"\n",
      " },\n",
      " {\n",
      "  \"sentence\": \"Salah satu penopang pertumbuhan laba BBHI adalah lonjakan  pendapatan bunga hingga 204% secara tahunan menjadi Rp313,63 miliar pada kuartal I 2023 dari Rp103,3 miliar pada periode yang sama di tahun sebelumnya.\",\n",
      "  \"aspect\": \"BBHI\",\n",
      "  \"sentiment\": \"Positive\"\n",
      " },\n",
      " {\n",
      "  \"sentence\": \"Namun sebaliknya BBHI juga mencatatkan peningkatan beban bunga sebesar 241% menjadi Rp76,55 miliar.\",\n",
      "  \"aspect\": \"BBHI\",\n",
      "  \"sentiment\": \"Positive\"\n",
      " },\n",
      " {\n",
      "  \"sentence\": \"Ipotnews - Emiten BBHI dan LPPF tercatat menjadi jawara dalam jajaran top gainers di indeks Kompas100 pada Rabu (7/6) pagi.\",\n",
      "  \"aspect\": \"LPPF\",\n",
      "  \"sentiment\": \"Positive\"\n",
      " },\n",
      " {\n",
      "  \"sentence\": \"Menyusul berikutnya adalah harga saham LPPF menguat 120 poin menjadi 3.410, atau naik 3,6%.\",\n",
      "  \"aspect\": \"LPPF\",\n",
      "  \"sentiment\": \"Positive\"\n",
      " },\n",
      " {\n",
      "  \"sentence\": \"Sementara itu, pada kuartal I 2023, PT Matahari Department Store Tbk (LPPF) memperluas bisnisnya dengan membuka dua gerai baru di Balikpapan, Kalimantan Timur dan Kuta, Bali.\",\n",
      "  \"aspect\": \"LPPF\",\n",
      "  \"sentiment\": \"Neutral\"\n",
      " }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "teks = \"\"\"Ipotnews - Emiten BBHI dan LPPF tercatat menjadi jawara dalam jajaran top gainers di indeks Kompas100 pada Rabu (7/6) pagi.\n",
    "Mengutip data IPOT 1 pukul 09.54 WIB, harga saham BBHI menguat 50 poin menjadi 1.125, atau naik 4,7%. Menyusul berikutnya adalah harga saham LPPF menguat 120 poin menjadi 3.410, atau naik 3,6%.\n",
    "Sebagaimana diketahui, emiten bank digital, PT Allo Bank Indonesia Tbk (BBHI) berhasil meningkatkan performa kinerja pada kuartal I 2023 dengan peningkatan laba.\n",
    "BBHI mencatatkan pertumbuhan laba bersih sepanjang tiga bulan pertama 2023 sebesar 21% secara tahunan (year-on-year/yoy) mencapai Rp90,49 miliar dari posisi sebelumnya Rp75 miliar.\n",
    "Salah satu penopang pertumbuhan laba BBHI adalah lonjakan  pendapatan bunga hingga 204% secara tahunan menjadi Rp313,63 miliar pada kuartal I 2023 dari Rp103,3 miliar pada periode yang sama di tahun sebelumnya.\n",
    "Namun sebaliknya BBHI juga mencatatkan peningkatan beban bunga sebesar 241% menjadi Rp76,55 miliar. Meskipun demikian, pendapatan bunga bersih bank tercatat tetap menebal 193% menjadi Rp237,08 miliar dibandingkan dengan kuartal I 2022 Rp80,83 miliar.\n",
    "Selain itu, angka kerugian penurunan nilai aset keuangan ( impairment ) Allobank juga susut 70% menjadi Rp3,94 miliar hingga Maret 2023, dari Rp13,21 miliar pada akhir Maret 2022.\n",
    "Sementara itu, pada kuartal I 2023, PT Matahari Department Store Tbk (LPPF) memperluas bisnisnya dengan membuka dua gerai baru di Balikpapan, Kalimantan Timur dan Kuta, Bali. Pembukaan gerai baru di Plaza Balikpapan dilakukan pada Rabu (05/04/2023) dan di Discovery Shopping Mall, Kuta, pada 6 April 2023.\n",
    "\"Dengan membawa tema 'Time To Grow' di tahun ini, kami membuka gerai baru keenam dan ketujuh dari program pembukaan gerai yang sudah direncanakan perseroan. Melalui dua gerai baru ini, kami ingin menghadirkan berbagai pilihan dan pengalaman berbelanja, serta menjadikan Matahari sebagai pilihan utama berbelanja di musim Lebaran ini,\" kata CEO Matahari Terry O'Connor dalam keterangan resminya, Rabu (5/4/2023).\n",
    "Dengan konsep baru yang lebih segar, menurut Terry, kedua toko ini menawarkan merchandise yang diperbarui dan pengalaman berbelanja pelanggan yang lebih baik. Matahari menggunakan sistem pencahayaan 100% LED sebagai komitmen perusahaan terhadap lingkungan.\n",
    "\"Kami percaya, kehadiran dua gerai dengan karakteristik modern ini akan menghadirkan pilihan belanja yang berbeda bagi masyarakat setempat,\" tutur dia.\n",
    "\"\"\"\n",
    "\n",
    "print(get_final_sentiment_artikel(teks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33384413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      " {\n",
      "  \"sentence\": \"Dalam RUPST ini pemegang saham juga menyetujui pengangkatan Ellen Kartika sebagai Direktur Investasi dan Portofolio menggantikan posisi Devin Antonio Ridwan, yang kini menjabat sebagai .en Direktur PT Merdeka Battery Materials Tbk (MBMA), anak perusahaan PT Merdeka Copper Gold Tbk (MDKA).\",\n",
      "  \"aspect\": \"MDKA\",\n",
      "  \"sentiment\": \"Neutral\"\n",
      " },\n",
      " {\n",
      "  \"sentence\": \"Ipotnews - PT .ent Investasi Bersama Tbk (PALM) akan melakukan buyback saham sebanyak-banyaknya 103.950.000 saham atau 1,46% dari seluruh modal ditempatkan dan disetor penuh.\",\n",
      "  \"aspect\": \"PALM\",\n",
      "  \"sentiment\": \"Positive\"\n",
      " },\n",
      " {\n",
      "  \"sentence\": \".en Direktur PALM, Tri Boewono mengungkapkan buyback saham tersebut dapat memberikan fleksibilitas yang lebih besar kepada perseroan dalam mengelola modal untuk mencapai struktur permodalan yang efisien untuk meningkatkan nilai pemegang saham.\",\n",
      "  \"aspect\": \"PALM\",\n",
      "  \"sentiment\": \"Positive\"\n",
      " }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "teks = \"\"\"Ipotnews - PT Provident Investasi Bersama Tbk (PALM) akan melakukan buyback saham sebanyak-banyaknya 103.950.000 saham atau 1,46% dari seluruh modal ditempatkan dan disetor penuh.\n",
    "Periode buyback saham mulai dilaksanakan dari 21 Juni 2023 sampai dengan 20 Juni 2024. Anggaran yang disiapkan perseroan untuk aksi korporasi ini sebesar Rp80,66 miliar.\n",
    "Presiden Direktur PALM, Tri Boewono mengungkapkan buyback saham tersebut dapat memberikan fleksibilitas yang lebih besar kepada perseroan dalam mengelola modal untuk mencapai struktur permodalan yang efisien untuk meningkatkan nilai pemegang saham.\n",
    "\"Kami berkeyakinan bahwa buyback tidak akan memberikan dampak negatif yang material terhadap kegiatan usaha Perseroan. Perseroan memiliki modal kerja dan arus kas (cash flow) yang memadai untuk melaksanakan pembiayaan transaksi bersamaan dengan kegiatan usaha Perseroan,\" ucapTrei Boewono dalam keterangannya, Rabu (21/6).\n",
    "Keputusan untuk melakukan buyback ini telah mendapat restu dari pemegang saham saat pelaksanaan RUPST pada Rabu (21/6).\n",
    "Dalam RUPST ini pemegang saham juga menyetujui pengangkatan Ellen Kartika sebagai Direktur Investasi dan Portofolio menggantikan posisi Devin Antonio Ridwan, yang kini menjabat sebagai Presiden Direktur PT Merdeka Battery Materials Tbk (MBMA), anak perusahaan PT Merdeka Copper Gold Tbk (MDKA). Perubahan komposisi ini akan mendukung strategi perseroan dalam mencari dan mengeksekusi peluang investasi di masa mendatang demi pertumbuhan kinerja Perseroan.\n",
    "\"Kami mengucapkan selamat kepada Ibu Ellen Kartika dan terima kasih atas kontribusi Bapak Devin Antonio Ridwan yang berperan besar dalam memajukan Perseroan hingga sampai pada posisi saat ini. Kami optimistis, dengan pengalaman panjang Ibu Ellen Kartika dalam investasi dan portofolio, akan juga membawa perubahan yang berkelanjutan bagi kinerja Perseroan,\" kata Tri Boewono.(Marjudin)\n",
    "Sumber : admin\"\"\"\n",
    "\n",
    "print(get_final_sentiment_artikel(teks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6604f8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
